import os
import logging
import json
import pandas as pd
import time
from typing import Dict
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Initialize the Mistral-Nemo-Instruct-2407 model and tokenizer
model_name = "mistralai/Mistral-Nemo-Instruct-2407"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map="auto")

def call_mistral_nemo(poll_data: Dict, system_prompt: str = """
You are an expert in analyzing political polls. Your task is to determine if a given poll is valid or not.
Consider the following criteria when evaluating poll validity:
1. Sample size: Ensure it's large enough to be statistically significant (typically >400 for national polls).
2. Polling methodology: Check if it's a scientifically sound method (e.g., random sampling).
3. Date of the poll: Verify it's within a reasonable timeframe before the election.
4. Pollster reputation: Consider the track record of the polling organization.
5. Demographic representation: Assess if the sample represents the voting population.
6. Margin of error: Evaluate if it's within acceptable limits (usually 3-5% for most polls).
7. Question wording: Ensure questions are clear, unbiased, and not leading.
8. Consistency: Compare with other polls from the same period for any significant outliers.

Respond with a JSON object containing a single key 'isValid' with a boolean value (true for valid, false for invalid).
Provide a brief explanation for your decision in the 'explanation' field.

Example response:
{
    "isValid": true,
    "explanation": "The poll has a sufficient sample size of 1000 respondents, uses random digit dialing, was conducted within two weeks of the election, and has a reputable pollster with a track record of accurate predictions."
}

Be thorough in your analysis and consistent in your judgments across different polls.
""") -> Dict:
    """
    Calls the Mistral-Nemo-Instruct-2407 model to generate a response to the given input.

    Args:
        poll_data (Dict): The input poll data for the language model.
        system_prompt (str): The system prompt for the language model.

    Returns:
        Dict: The parsed response generated by the language model.
    """
    try:
        logging.info(f"Calling Mistral-Nemo-Instruct-2407 model for poll: {poll_data.get('Poll', 'Unknown')}")

        # Prepare the input prompt
        prompt = f"{system_prompt}\n\nPoll data:\n{json.dumps(poll_data, indent=2)}\n\nAnalyze the poll data and provide your response:"

        # Generate response using the model
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        with torch.no_grad():
            outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.2, top_p=0.95, top_k=64)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        # Parse the response
        try:
            parsed_response = json.loads(response)
        except json.JSONDecodeError:
            logging.error(f"Failed to parse model response as JSON: {response}")
            parsed_response = {"isValid": None, "explanation": "Error: Unable to parse model response"}

        logging.info(f"Model call successful for poll: {poll_data.get('Poll', 'Unknown')}")
        return parsed_response
    except Exception as e:
        logging.error(f"Error calling Mistral-Nemo-Instruct-2407 model: {str(e)}")
        return {"isValid": None, "explanation": f"Error: {str(e)}"}

def process_election_years():
    input_dir = 'data/intermediate/polling'
    for filename in os.listdir(input_dir):
        if filename.endswith('_isvalid_llm.csv'):
            input_file = os.path.join(input_dir, filename)
            output_file = os.path.join(input_dir, filename.replace('_isvalid_llm.csv', '_isvalid_llm_updated.csv'))

            df = pd.read_csv(input_file)
            total_polls = len(df)
            logging.info(f"Processing {total_polls} polls for file {filename}")

            results = []
            for index, row in df.iterrows():
                try:
                    poll_data = row.to_dict()
                    prompt = create_prompt(poll_data)
                    response = call_mistral_nemo(prompt)
                    parsed_response = parse_mistral_response(response)
                    results.append(parsed_response)
                    if (index + 1) % 10 == 0:
                        logging.info(f"Processed {index + 1}/{total_polls} polls for file {filename}")
                except Exception as e:
                    logging.error(f"Error processing poll {index + 1} for file {filename}: {str(e)}")
                    results.append({"isValid": None, "explanation": f"Error: {str(e)}"})

                # Add a small delay to avoid overwhelming the model
                time.sleep(0.1)

            df['isValid'] = [r.get('isValid') for r in results]
            df['explanation'] = [r.get('explanation') for r in results]
            df.to_csv(output_file, index=False)
            logging.info(f"Completed processing for file {filename}. Output saved to {output_file}")

def create_prompt(poll_data):
    return f"""Analyze the following poll data and determine if it's valid:
{json.dumps(poll_data, indent=2)}
Respond with a JSON object containing 'isValid' (boolean) and 'explanation' (string) fields."""

def parse_mistral_response(response):
    try:
        # Extract JSON from the response
        json_start = response.find('{')
        json_end = response.rfind('}') + 1
        json_str = response[json_start:json_end]
        parsed = json.loads(json_str)
        return {
            "isValid": parsed.get("isValid"),
            "explanation": parsed.get("explanation")
        }
    except json.JSONDecodeError:
        logging.error(f"Failed to parse JSON from response: {response}")
        return {"isValid": None, "explanation": "Error: Failed to parse model response"}

if __name__ == "__main__":
    process_election_years()
